{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from sqlalchemy import create_engine\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy.stats import gmean\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.base import BaseEstimator,TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "database_filepath = \"../data/disaster_response.db\"\n",
    "engine = create_engine('sqlite:///' + database_filepath)\n",
    "table_name = os.path.basename(database_filepath).replace(\".db\",\"\") + \"_table\"\n",
    "df = pd.read_sql_table(table_name,engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>water</th>\n",
       "      <th>food</th>\n",
       "      <th>shelter</th>\n",
       "      <th>clothing</th>\n",
       "      <th>money</th>\n",
       "      <th>missing_people</th>\n",
       "      <th>refugees</th>\n",
       "      <th>death</th>\n",
       "      <th>other_aid</th>\n",
       "      <th>infrastructure_related</th>\n",
       "      <th>transport</th>\n",
       "      <th>buildings</th>\n",
       "      <th>electricity</th>\n",
       "      <th>tools</th>\n",
       "      <th>hospitals</th>\n",
       "      <th>shops</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26216.00000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.0</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15224.82133</td>\n",
       "      <td>0.773650</td>\n",
       "      <td>0.170659</td>\n",
       "      <td>0.004501</td>\n",
       "      <td>0.414251</td>\n",
       "      <td>0.079493</td>\n",
       "      <td>0.050084</td>\n",
       "      <td>0.027617</td>\n",
       "      <td>0.017966</td>\n",
       "      <td>0.032804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063778</td>\n",
       "      <td>0.111497</td>\n",
       "      <td>0.088267</td>\n",
       "      <td>0.015449</td>\n",
       "      <td>0.023039</td>\n",
       "      <td>0.011367</td>\n",
       "      <td>0.033377</td>\n",
       "      <td>0.045545</td>\n",
       "      <td>0.131446</td>\n",
       "      <td>0.065037</td>\n",
       "      <td>0.045812</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.020293</td>\n",
       "      <td>0.006065</td>\n",
       "      <td>0.010795</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.011787</td>\n",
       "      <td>0.043904</td>\n",
       "      <td>0.278341</td>\n",
       "      <td>0.082202</td>\n",
       "      <td>0.093187</td>\n",
       "      <td>0.010757</td>\n",
       "      <td>0.093645</td>\n",
       "      <td>0.020217</td>\n",
       "      <td>0.052487</td>\n",
       "      <td>0.193584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8826.88914</td>\n",
       "      <td>0.435276</td>\n",
       "      <td>0.376218</td>\n",
       "      <td>0.066940</td>\n",
       "      <td>0.492602</td>\n",
       "      <td>0.270513</td>\n",
       "      <td>0.218122</td>\n",
       "      <td>0.163875</td>\n",
       "      <td>0.132831</td>\n",
       "      <td>0.178128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244361</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.283688</td>\n",
       "      <td>0.123331</td>\n",
       "      <td>0.150031</td>\n",
       "      <td>0.106011</td>\n",
       "      <td>0.179621</td>\n",
       "      <td>0.208500</td>\n",
       "      <td>0.337894</td>\n",
       "      <td>0.246595</td>\n",
       "      <td>0.209081</td>\n",
       "      <td>0.219689</td>\n",
       "      <td>0.141003</td>\n",
       "      <td>0.077643</td>\n",
       "      <td>0.103338</td>\n",
       "      <td>0.067502</td>\n",
       "      <td>0.107927</td>\n",
       "      <td>0.204887</td>\n",
       "      <td>0.448191</td>\n",
       "      <td>0.274677</td>\n",
       "      <td>0.290700</td>\n",
       "      <td>0.103158</td>\n",
       "      <td>0.291340</td>\n",
       "      <td>0.140743</td>\n",
       "      <td>0.223011</td>\n",
       "      <td>0.395114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7446.75000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15662.50000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22924.25000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30265.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       related       request         offer   aid_related  \\\n",
       "count  26216.00000  26216.000000  26216.000000  26216.000000  26216.000000   \n",
       "mean   15224.82133      0.773650      0.170659      0.004501      0.414251   \n",
       "std     8826.88914      0.435276      0.376218      0.066940      0.492602   \n",
       "min        2.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%     7446.75000      1.000000      0.000000      0.000000      0.000000   \n",
       "50%    15662.50000      1.000000      0.000000      0.000000      0.000000   \n",
       "75%    22924.25000      1.000000      0.000000      0.000000      1.000000   \n",
       "max    30265.00000      2.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       medical_help  medical_products  search_and_rescue      security  \\\n",
       "count  26216.000000      26216.000000       26216.000000  26216.000000   \n",
       "mean       0.079493          0.050084           0.027617      0.017966   \n",
       "std        0.270513          0.218122           0.163875      0.132831   \n",
       "min        0.000000          0.000000           0.000000      0.000000   \n",
       "25%        0.000000          0.000000           0.000000      0.000000   \n",
       "50%        0.000000          0.000000           0.000000      0.000000   \n",
       "75%        0.000000          0.000000           0.000000      0.000000   \n",
       "max        1.000000          1.000000           1.000000      1.000000   \n",
       "\n",
       "           military  child_alone         water          food       shelter  \\\n",
       "count  26216.000000      26216.0  26216.000000  26216.000000  26216.000000   \n",
       "mean       0.032804          0.0      0.063778      0.111497      0.088267   \n",
       "std        0.178128          0.0      0.244361      0.314752      0.283688   \n",
       "min        0.000000          0.0      0.000000      0.000000      0.000000   \n",
       "25%        0.000000          0.0      0.000000      0.000000      0.000000   \n",
       "50%        0.000000          0.0      0.000000      0.000000      0.000000   \n",
       "75%        0.000000          0.0      0.000000      0.000000      0.000000   \n",
       "max        1.000000          0.0      1.000000      1.000000      1.000000   \n",
       "\n",
       "           clothing         money  missing_people      refugees         death  \\\n",
       "count  26216.000000  26216.000000    26216.000000  26216.000000  26216.000000   \n",
       "mean       0.015449      0.023039        0.011367      0.033377      0.045545   \n",
       "std        0.123331      0.150031        0.106011      0.179621      0.208500   \n",
       "min        0.000000      0.000000        0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000        0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000        0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000        0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000        1.000000      1.000000      1.000000   \n",
       "\n",
       "          other_aid  infrastructure_related     transport     buildings  \\\n",
       "count  26216.000000            26216.000000  26216.000000  26216.000000   \n",
       "mean       0.131446                0.065037      0.045812      0.050847   \n",
       "std        0.337894                0.246595      0.209081      0.219689   \n",
       "min        0.000000                0.000000      0.000000      0.000000   \n",
       "25%        0.000000                0.000000      0.000000      0.000000   \n",
       "50%        0.000000                0.000000      0.000000      0.000000   \n",
       "75%        0.000000                0.000000      0.000000      0.000000   \n",
       "max        1.000000                1.000000      1.000000      1.000000   \n",
       "\n",
       "        electricity         tools     hospitals         shops   aid_centers  \\\n",
       "count  26216.000000  26216.000000  26216.000000  26216.000000  26216.000000   \n",
       "mean       0.020293      0.006065      0.010795      0.004577      0.011787   \n",
       "std        0.141003      0.077643      0.103338      0.067502      0.107927   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       other_infrastructure  weather_related        floods         storm  \\\n",
       "count          26216.000000     26216.000000  26216.000000  26216.000000   \n",
       "mean               0.043904         0.278341      0.082202      0.093187   \n",
       "std                0.204887         0.448191      0.274677      0.290700   \n",
       "min                0.000000         0.000000      0.000000      0.000000   \n",
       "25%                0.000000         0.000000      0.000000      0.000000   \n",
       "50%                0.000000         0.000000      0.000000      0.000000   \n",
       "75%                0.000000         1.000000      0.000000      0.000000   \n",
       "max                1.000000         1.000000      1.000000      1.000000   \n",
       "\n",
       "               fire    earthquake          cold  other_weather  direct_report  \n",
       "count  26216.000000  26216.000000  26216.000000   26216.000000   26216.000000  \n",
       "mean       0.010757      0.093645      0.020217       0.052487       0.193584  \n",
       "std        0.103158      0.291340      0.140743       0.223011       0.395114  \n",
       "min        0.000000      0.000000      0.000000       0.000000       0.000000  \n",
       "25%        0.000000      0.000000      0.000000       0.000000       0.000000  \n",
       "50%        0.000000      0.000000      0.000000       0.000000       0.000000  \n",
       "75%        0.000000      0.000000      0.000000       0.000000       0.000000  \n",
       "max        1.000000      1.000000      1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove child alone field because it has all zeros only\n",
    "df = df.drop(['child_alone'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of 2's in the related field\n",
    "df['related'].eq(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 2 with 1 to consider it a valid response(binary).\n",
    "df['related']=df['related'].map(lambda x: 1 if x == 2 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract X and y variables from the data for the modelling\n",
    "X = df['message']\n",
    "#select from columns with categorical values 0 or 1\n",
    "y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text,url_place_holder_string=\"urlplaceholder\"):\n",
    "    \"\"\"\n",
    "    function to tokenize and normalize text data\n",
    "    \n",
    "    Arguments:\n",
    "        text -> messages to be tokenized and normalized\n",
    "    Output:\n",
    "        normalized -> List of tokens extracted and normalized from the messages\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace all urls with a urlplaceholder string\n",
    "    url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    \n",
    "    # Extract all the urls from the provided text \n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    \n",
    "    # Replace url with a url placeholder string\n",
    "    for detected_url in detected_urls:\n",
    "        text = text.replace(detected_url, url_place_holder_string)\n",
    "\n",
    "    # Extract the word tokens from the provided text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    #Lemmanitizer to remove inflectional and derivationally related forms of a word\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "    # List of clean tokens\n",
    "    normalized = [lemmatizer.lemmatize(w).lower().strip() for w in tokens]\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a custom transformer which will extract the starting verb of a sentence\n",
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    The class for implementing Verb Extractor\n",
    "    \n",
    "    This class extract the starting verb of a sentence,\n",
    "    creating a new feature for the ML classifier\n",
    "    \"\"\"\n",
    "\n",
    "    def starting_verb(self, text):\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        for sentence in sentence_list:\n",
    "            pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "            first_word, first_tag = pos_tags[0]\n",
    "            if first_tag in ['VB', 'VBP'] or first_word == 'RT':\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        return pd.DataFrame(X_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_one = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('count_vectorizer', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf_transformer', TfidfTransformer())\n",
    "            ]))\n",
    "            \n",
    "        ])),\n",
    "\n",
    "        ('classifier', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "    ])\n",
    "\n",
    "pipeline_two = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('count_vectorizer', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf_transformer', TfidfTransformer())\n",
    "            ])),\n",
    "\n",
    "            ('starting_verb_transformer', StartingVerbExtractor())\n",
    "        ])),\n",
    "\n",
    "        ('classifier', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "pipeline_fitted = pipeline_one.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.94      0.88      5075\n",
      "               request       0.77      0.57      0.66      1148\n",
      "                 offer       0.08      0.03      0.04        36\n",
      "           aid_related       0.76      0.60      0.67      2709\n",
      "          medical_help       0.62      0.28      0.39       513\n",
      "      medical_products       0.61      0.32      0.42       314\n",
      "     search_and_rescue       0.64      0.25      0.36       173\n",
      "              security       0.23      0.07      0.10       107\n",
      "              military       0.57      0.31      0.40       203\n",
      "                 water       0.73      0.66      0.69       420\n",
      "                  food       0.80      0.68      0.73       742\n",
      "               shelter       0.77      0.58      0.66       577\n",
      "              clothing       0.59      0.39      0.47        98\n",
      "                 money       0.60      0.23      0.33       159\n",
      "        missing_people       0.52      0.16      0.24        75\n",
      "              refugees       0.56      0.26      0.35       205\n",
      "                 death       0.74      0.51      0.60       278\n",
      "             other_aid       0.53      0.14      0.23       879\n",
      "infrastructure_related       0.51      0.08      0.14       439\n",
      "             transport       0.75      0.28      0.41       308\n",
      "             buildings       0.67      0.38      0.48       346\n",
      "           electricity       0.54      0.32      0.40       138\n",
      "                 tools       0.20      0.03      0.05        38\n",
      "             hospitals       0.24      0.06      0.09        72\n",
      "                 shops       0.00      0.00      0.00        30\n",
      "           aid_centers       0.35      0.09      0.15        74\n",
      "  other_infrastructure       0.41      0.09      0.14       294\n",
      "       weather_related       0.85      0.65      0.74      1847\n",
      "                floods       0.88      0.55      0.68       558\n",
      "                 storm       0.76      0.47      0.59       656\n",
      "                  fire       0.51      0.30      0.38        69\n",
      "            earthquake       0.86      0.77      0.81       584\n",
      "                  cold       0.67      0.32      0.43       139\n",
      "         other_weather       0.44      0.18      0.26       333\n",
      "         direct_report       0.76      0.49      0.60      1343\n",
      "\n",
      "             micro avg       0.78      0.59      0.67     20979\n",
      "             macro avg       0.58      0.34      0.42     20979\n",
      "          weighted avg       0.74      0.59      0.64     20979\n",
      "           samples avg       0.65      0.52      0.53     20979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prediction_train = pipeline_fitted.predict(X_train)\n",
    "y_prediction_test = pipeline_fitted.predict(X_test)\n",
    "\n",
    "# Print classification report on test data\n",
    "print(classification_report(y_test.values, y_prediction_test, target_names=y.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.94      0.88     15019\n",
      "               request       0.79      0.56      0.65      3326\n",
      "                 offer       0.47      0.09      0.14        82\n",
      "           aid_related       0.76      0.60      0.67      8151\n",
      "          medical_help       0.65      0.28      0.39      1571\n",
      "      medical_products       0.70      0.36      0.47       999\n",
      "     search_and_rescue       0.66      0.22      0.33       551\n",
      "              security       0.52      0.09      0.16       364\n",
      "              military       0.68      0.37      0.47       657\n",
      "                 water       0.77      0.67      0.72      1252\n",
      "                  food       0.82      0.69      0.75      2181\n",
      "               shelter       0.79      0.54      0.64      1737\n",
      "              clothing       0.77      0.49      0.60       307\n",
      "                 money       0.66      0.33      0.44       445\n",
      "        missing_people       0.69      0.19      0.30       223\n",
      "              refugees       0.66      0.29      0.40       670\n",
      "                 death       0.79      0.50      0.61       916\n",
      "             other_aid       0.58      0.16      0.25      2567\n",
      "infrastructure_related       0.51      0.10      0.17      1266\n",
      "             transport       0.64      0.26      0.37       893\n",
      "             buildings       0.70      0.41      0.52       987\n",
      "           electricity       0.67      0.36      0.47       394\n",
      "                 tools       0.43      0.07      0.13       121\n",
      "             hospitals       0.53      0.12      0.20       211\n",
      "                 shops       0.44      0.04      0.08        90\n",
      "           aid_centers       0.46      0.14      0.21       235\n",
      "  other_infrastructure       0.48      0.10      0.17       857\n",
      "       weather_related       0.87      0.65      0.75      5450\n",
      "                floods       0.89      0.56      0.69      1597\n",
      "                 storm       0.80      0.48      0.60      1787\n",
      "                  fire       0.73      0.31      0.43       213\n",
      "            earthquake       0.90      0.79      0.84      1871\n",
      "                  cold       0.74      0.32      0.45       391\n",
      "         other_weather       0.58      0.20      0.30      1043\n",
      "         direct_report       0.74      0.48      0.59      3732\n",
      "\n",
      "             micro avg       0.79      0.59      0.68     62156\n",
      "             macro avg       0.68      0.37      0.45     62156\n",
      "          weighted avg       0.76      0.59      0.65     62156\n",
      "           samples avg       0.64      0.51      0.53     62156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report on training data\n",
    "print('\\n',classification_report(y_train.values, y_prediction_train, target_names=y.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('text_pipeline',\n",
       "                                                                        Pipeline(steps=[('count_vectorizer',\n",
       "                                                                                         CountVectorizer(tokenizer=<function tokenize at 0x136bc8170>)),\n",
       "                                                                                        ('tfidf_transformer',\n",
       "                                                                                         TfidfTransformer())]))])),\n",
       "                                       ('classifier',\n",
       "                                        MultiOutputClassifier(estimator=AdaBoostClassifier()))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__estimator__learning_rate': [0.01, 0.02,\n",
       "                                                                  0.05],\n",
       "                         'classifier__estimator__n_estimators': [10, 20, 40]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline_one.get_params().keys()\n",
    "parameters_grid = {'classifier__estimator__learning_rate': [0.01, 0.02, 0.05],\n",
    "              'classifier__estimator__n_estimators': [10, 20, 40]}\n",
    "\n",
    "#parameters_grid = {'classifier__estimator__n_estimators': [10, 20, 40]}\n",
    "\n",
    "cv = GridSearchCV(pipeline_one, param_grid=parameters_grid, scoring='f1_micro', n_jobs=-1)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction values from the grid search cross validator\n",
    "y_prediction_test = cv.predict(X_test)\n",
    "y_prediction_train = cv.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.77      1.00      0.87      5075\n",
      "               request       0.61      0.40      0.48      1148\n",
      "                 offer       0.00      0.00      0.00        36\n",
      "           aid_related       0.80      0.19      0.31      2709\n",
      "          medical_help       0.70      0.12      0.21       513\n",
      "      medical_products       0.68      0.11      0.20       314\n",
      "     search_and_rescue       0.60      0.20      0.30       173\n",
      "              security       0.00      0.00      0.00       107\n",
      "              military       0.00      0.00      0.00       203\n",
      "                 water       0.58      0.83      0.68       420\n",
      "                  food       0.77      0.68      0.72       742\n",
      "               shelter       0.83      0.29      0.43       577\n",
      "              clothing       0.64      0.23      0.34        98\n",
      "                 money       1.00      0.02      0.04       159\n",
      "        missing_people       0.66      0.25      0.37        75\n",
      "              refugees       0.75      0.03      0.06       205\n",
      "                 death       0.81      0.16      0.27       278\n",
      "             other_aid       0.00      0.00      0.00       879\n",
      "infrastructure_related       0.00      0.00      0.00       439\n",
      "             transport       0.61      0.25      0.36       308\n",
      "             buildings       0.00      0.00      0.00       346\n",
      "           electricity       0.00      0.00      0.00       138\n",
      "                 tools       0.00      0.00      0.00        38\n",
      "             hospitals       0.00      0.00      0.00        72\n",
      "                 shops       0.00      0.00      0.00        30\n",
      "           aid_centers       0.00      0.00      0.00        74\n",
      "  other_infrastructure       0.00      0.00      0.00       294\n",
      "       weather_related       0.89      0.21      0.34      1847\n",
      "                floods       0.92      0.34      0.49       558\n",
      "                 storm       0.74      0.27      0.40       656\n",
      "                  fire       0.47      0.43      0.45        69\n",
      "            earthquake       0.87      0.66      0.75       584\n",
      "                  cold       0.76      0.24      0.37       139\n",
      "         other_weather       0.51      0.11      0.18       333\n",
      "         direct_report       0.65      0.39      0.49      1343\n",
      "\n",
      "             micro avg       0.75      0.44      0.55     20979\n",
      "             macro avg       0.47      0.21      0.26     20979\n",
      "          weighted avg       0.66      0.44      0.47     20979\n",
      "           samples avg       0.71      0.45      0.50     20979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report on test data\n",
    "print(classification_report(y_test.values, y_prediction_test, target_names=y.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               related       0.76      1.00      0.87     15019\n",
      "               request       0.61      0.37      0.46      3326\n",
      "                 offer       1.00      0.02      0.05        82\n",
      "           aid_related       0.80      0.19      0.31      8151\n",
      "          medical_help       0.61      0.11      0.19      1571\n",
      "      medical_products       0.74      0.13      0.22       999\n",
      "     search_and_rescue       0.65      0.19      0.29       551\n",
      "              security       0.00      0.00      0.00       364\n",
      "              military       0.50      0.00      0.01       657\n",
      "                 water       0.58      0.85      0.69      1252\n",
      "                  food       0.77      0.68      0.72      2181\n",
      "               shelter       0.85      0.30      0.44      1737\n",
      "              clothing       0.80      0.34      0.47       307\n",
      "                 money       1.00      0.00      0.00       445\n",
      "        missing_people       0.70      0.25      0.36       223\n",
      "              refugees       0.70      0.01      0.02       670\n",
      "                 death       0.73      0.17      0.27       916\n",
      "             other_aid       0.00      0.00      0.00      2567\n",
      "infrastructure_related       0.00      0.00      0.00      1266\n",
      "             transport       0.57      0.25      0.35       893\n",
      "             buildings       0.00      0.00      0.00       987\n",
      "           electricity       0.00      0.00      0.00       394\n",
      "                 tools       0.00      0.00      0.00       121\n",
      "             hospitals       0.00      0.00      0.00       211\n",
      "                 shops       0.00      0.00      0.00        90\n",
      "           aid_centers       0.00      0.00      0.00       235\n",
      "  other_infrastructure       0.00      0.00      0.00       857\n",
      "       weather_related       0.92      0.23      0.36      5450\n",
      "                floods       0.91      0.34      0.49      1597\n",
      "                 storm       0.73      0.25      0.38      1787\n",
      "                  fire       0.53      0.39      0.45       213\n",
      "            earthquake       0.90      0.65      0.75      1871\n",
      "                  cold       0.66      0.21      0.32       391\n",
      "         other_weather       0.60      0.12      0.20      1043\n",
      "         direct_report       0.63      0.39      0.48      3732\n",
      "\n",
      "             micro avg       0.75      0.43      0.55     62156\n",
      "             macro avg       0.52      0.21      0.26     62156\n",
      "          weighted avg       0.67      0.43      0.46     62156\n",
      "           samples avg       0.71      0.44      0.49     62156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report on training data\n",
    "print('\\n',classification_report(y_train.values, y_prediction_train, target_names=y.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.94      0.88      5032\n",
      "               request       0.76      0.55      0.64      1076\n",
      "                 offer       0.00      0.00      0.00        30\n",
      "           aid_related       0.75      0.59      0.66      2653\n",
      "          medical_help       0.63      0.25      0.36       504\n",
      "      medical_products       0.68      0.34      0.45       313\n",
      "     search_and_rescue       0.67      0.24      0.36       165\n",
      "              security       0.37      0.09      0.14       111\n",
      "              military       0.66      0.35      0.46       224\n",
      "                 water       0.71      0.61      0.66       417\n",
      "                  food       0.79      0.69      0.74       745\n",
      "               shelter       0.79      0.54      0.64       566\n",
      "              clothing       0.70      0.57      0.63        91\n",
      "                 money       0.45      0.33      0.38       122\n",
      "        missing_people       0.54      0.20      0.29        66\n",
      "              refugees       0.67      0.24      0.35       202\n",
      "                 death       0.78      0.39      0.52       294\n",
      "             other_aid       0.44      0.13      0.21       810\n",
      "infrastructure_related       0.42      0.09      0.14       425\n",
      "             transport       0.67      0.24      0.35       276\n",
      "             buildings       0.69      0.38      0.49       343\n",
      "           electricity       0.57      0.25      0.35       145\n",
      "                 tools       0.00      0.00      0.00        41\n",
      "             hospitals       0.31      0.12      0.17        69\n",
      "                 shops       0.00      0.00      0.00        30\n",
      "           aid_centers       0.28      0.13      0.17        79\n",
      "  other_infrastructure       0.40      0.10      0.16       283\n",
      "       weather_related       0.85      0.64      0.73      1834\n",
      "                floods       0.86      0.55      0.67       543\n",
      "                 storm       0.78      0.57      0.66       627\n",
      "                  fire       0.43      0.17      0.25        69\n",
      "            earthquake       0.87      0.76      0.81       612\n",
      "                  cold       0.63      0.31      0.41       121\n",
      "         other_weather       0.42      0.10      0.16       346\n",
      "         direct_report       0.71      0.48      0.57      1234\n",
      "\n",
      "             micro avg       0.77      0.59      0.67     20498\n",
      "             macro avg       0.57      0.34      0.41     20498\n",
      "          weighted avg       0.73      0.59      0.63     20498\n",
      "           samples avg       0.64      0.51      0.52     20498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use pipeline_two which includes StartingVerbEstimator\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "pipeline_fitted = pipeline_two.fit(X_train, y_train)\n",
    "\n",
    "y_prediction_train = pipeline_fitted.predict(X_train)\n",
    "y_prediction_test = pipeline_fitted.predict(X_test)\n",
    "\n",
    "# Print classification report on test data\n",
    "print(classification_report(y_test.values, y_prediction_test, target_names=y.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.94      0.88     15062\n",
      "               request       0.78      0.56      0.65      3398\n",
      "                 offer       0.42      0.11      0.18        88\n",
      "           aid_related       0.78      0.61      0.68      8207\n",
      "          medical_help       0.65      0.28      0.39      1580\n",
      "      medical_products       0.71      0.35      0.47      1000\n",
      "     search_and_rescue       0.67      0.20      0.30       559\n",
      "              security       0.55      0.09      0.15       360\n",
      "              military       0.68      0.36      0.47       636\n",
      "                 water       0.78      0.67      0.72      1255\n",
      "                  food       0.82      0.70      0.75      2178\n",
      "               shelter       0.80      0.54      0.64      1748\n",
      "              clothing       0.77      0.48      0.59       314\n",
      "                 money       0.66      0.34      0.45       482\n",
      "        missing_people       0.73      0.19      0.30       232\n",
      "              refugees       0.60      0.26      0.36       673\n",
      "                 death       0.78      0.49      0.60       900\n",
      "             other_aid       0.57      0.16      0.25      2636\n",
      "infrastructure_related       0.53      0.11      0.18      1280\n",
      "             transport       0.71      0.26      0.38       925\n",
      "             buildings       0.69      0.41      0.51       990\n",
      "           electricity       0.69      0.35      0.46       387\n",
      "                 tools       0.60      0.10      0.17       118\n",
      "             hospitals       0.48      0.11      0.18       214\n",
      "                 shops       0.60      0.10      0.17        90\n",
      "           aid_centers       0.45      0.13      0.20       230\n",
      "  other_infrastructure       0.48      0.09      0.15       868\n",
      "       weather_related       0.86      0.66      0.75      5463\n",
      "                floods       0.88      0.57      0.69      1612\n",
      "                 storm       0.78      0.54      0.64      1816\n",
      "                  fire       0.76      0.36      0.49       213\n",
      "            earthquake       0.89      0.78      0.83      1843\n",
      "                  cold       0.78      0.38      0.51       409\n",
      "         other_weather       0.59      0.16      0.25      1030\n",
      "         direct_report       0.76      0.50      0.60      3841\n",
      "\n",
      "             micro avg       0.80      0.59      0.68     62637\n",
      "             macro avg       0.69      0.37      0.46     62637\n",
      "          weighted avg       0.77      0.59      0.65     62637\n",
      "           samples avg       0.65      0.51      0.53     62637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report on training data\n",
    "print('\\n',classification_report(y_train.values, y_prediction_train, target_names=y.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_file = pickle.dumps('../models/classifier.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disasterresponse-env",
   "language": "python",
   "name": "disasterresponse-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
