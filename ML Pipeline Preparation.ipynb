{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from sqlalchemy import create_engine\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy.stats import gmean\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.base import BaseEstimator,TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "database_filepath = \"disaster_response.db\"\n",
    "engine = create_engine('sqlite:///' + database_filepath)\n",
    "table_name = os.path.basename(database_filepath).replace(\".db\",\"\") + \"_table\"\n",
    "df = pd.read_sql_table(table_name,engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>water</th>\n",
       "      <th>food</th>\n",
       "      <th>shelter</th>\n",
       "      <th>clothing</th>\n",
       "      <th>money</th>\n",
       "      <th>missing_people</th>\n",
       "      <th>refugees</th>\n",
       "      <th>death</th>\n",
       "      <th>other_aid</th>\n",
       "      <th>infrastructure_related</th>\n",
       "      <th>transport</th>\n",
       "      <th>buildings</th>\n",
       "      <th>electricity</th>\n",
       "      <th>tools</th>\n",
       "      <th>hospitals</th>\n",
       "      <th>shops</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26216.00000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.0</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "      <td>26216.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15224.82133</td>\n",
       "      <td>0.773650</td>\n",
       "      <td>0.170659</td>\n",
       "      <td>0.004501</td>\n",
       "      <td>0.414251</td>\n",
       "      <td>0.079493</td>\n",
       "      <td>0.050084</td>\n",
       "      <td>0.027617</td>\n",
       "      <td>0.017966</td>\n",
       "      <td>0.032804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063778</td>\n",
       "      <td>0.111497</td>\n",
       "      <td>0.088267</td>\n",
       "      <td>0.015449</td>\n",
       "      <td>0.023039</td>\n",
       "      <td>0.011367</td>\n",
       "      <td>0.033377</td>\n",
       "      <td>0.045545</td>\n",
       "      <td>0.131446</td>\n",
       "      <td>0.065037</td>\n",
       "      <td>0.045812</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.020293</td>\n",
       "      <td>0.006065</td>\n",
       "      <td>0.010795</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.011787</td>\n",
       "      <td>0.043904</td>\n",
       "      <td>0.278341</td>\n",
       "      <td>0.082202</td>\n",
       "      <td>0.093187</td>\n",
       "      <td>0.010757</td>\n",
       "      <td>0.093645</td>\n",
       "      <td>0.020217</td>\n",
       "      <td>0.052487</td>\n",
       "      <td>0.193584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8826.88914</td>\n",
       "      <td>0.435276</td>\n",
       "      <td>0.376218</td>\n",
       "      <td>0.066940</td>\n",
       "      <td>0.492602</td>\n",
       "      <td>0.270513</td>\n",
       "      <td>0.218122</td>\n",
       "      <td>0.163875</td>\n",
       "      <td>0.132831</td>\n",
       "      <td>0.178128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244361</td>\n",
       "      <td>0.314752</td>\n",
       "      <td>0.283688</td>\n",
       "      <td>0.123331</td>\n",
       "      <td>0.150031</td>\n",
       "      <td>0.106011</td>\n",
       "      <td>0.179621</td>\n",
       "      <td>0.208500</td>\n",
       "      <td>0.337894</td>\n",
       "      <td>0.246595</td>\n",
       "      <td>0.209081</td>\n",
       "      <td>0.219689</td>\n",
       "      <td>0.141003</td>\n",
       "      <td>0.077643</td>\n",
       "      <td>0.103338</td>\n",
       "      <td>0.067502</td>\n",
       "      <td>0.107927</td>\n",
       "      <td>0.204887</td>\n",
       "      <td>0.448191</td>\n",
       "      <td>0.274677</td>\n",
       "      <td>0.290700</td>\n",
       "      <td>0.103158</td>\n",
       "      <td>0.291340</td>\n",
       "      <td>0.140743</td>\n",
       "      <td>0.223011</td>\n",
       "      <td>0.395114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7446.75000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15662.50000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22924.25000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30265.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       related       request         offer   aid_related  \\\n",
       "count  26216.00000  26216.000000  26216.000000  26216.000000  26216.000000   \n",
       "mean   15224.82133      0.773650      0.170659      0.004501      0.414251   \n",
       "std     8826.88914      0.435276      0.376218      0.066940      0.492602   \n",
       "min        2.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%     7446.75000      1.000000      0.000000      0.000000      0.000000   \n",
       "50%    15662.50000      1.000000      0.000000      0.000000      0.000000   \n",
       "75%    22924.25000      1.000000      0.000000      0.000000      1.000000   \n",
       "max    30265.00000      2.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       medical_help  medical_products  search_and_rescue      security  \\\n",
       "count  26216.000000      26216.000000       26216.000000  26216.000000   \n",
       "mean       0.079493          0.050084           0.027617      0.017966   \n",
       "std        0.270513          0.218122           0.163875      0.132831   \n",
       "min        0.000000          0.000000           0.000000      0.000000   \n",
       "25%        0.000000          0.000000           0.000000      0.000000   \n",
       "50%        0.000000          0.000000           0.000000      0.000000   \n",
       "75%        0.000000          0.000000           0.000000      0.000000   \n",
       "max        1.000000          1.000000           1.000000      1.000000   \n",
       "\n",
       "           military  child_alone         water          food       shelter  \\\n",
       "count  26216.000000      26216.0  26216.000000  26216.000000  26216.000000   \n",
       "mean       0.032804          0.0      0.063778      0.111497      0.088267   \n",
       "std        0.178128          0.0      0.244361      0.314752      0.283688   \n",
       "min        0.000000          0.0      0.000000      0.000000      0.000000   \n",
       "25%        0.000000          0.0      0.000000      0.000000      0.000000   \n",
       "50%        0.000000          0.0      0.000000      0.000000      0.000000   \n",
       "75%        0.000000          0.0      0.000000      0.000000      0.000000   \n",
       "max        1.000000          0.0      1.000000      1.000000      1.000000   \n",
       "\n",
       "           clothing         money  missing_people      refugees         death  \\\n",
       "count  26216.000000  26216.000000    26216.000000  26216.000000  26216.000000   \n",
       "mean       0.015449      0.023039        0.011367      0.033377      0.045545   \n",
       "std        0.123331      0.150031        0.106011      0.179621      0.208500   \n",
       "min        0.000000      0.000000        0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000        0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000        0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000        0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000        1.000000      1.000000      1.000000   \n",
       "\n",
       "          other_aid  infrastructure_related     transport     buildings  \\\n",
       "count  26216.000000            26216.000000  26216.000000  26216.000000   \n",
       "mean       0.131446                0.065037      0.045812      0.050847   \n",
       "std        0.337894                0.246595      0.209081      0.219689   \n",
       "min        0.000000                0.000000      0.000000      0.000000   \n",
       "25%        0.000000                0.000000      0.000000      0.000000   \n",
       "50%        0.000000                0.000000      0.000000      0.000000   \n",
       "75%        0.000000                0.000000      0.000000      0.000000   \n",
       "max        1.000000                1.000000      1.000000      1.000000   \n",
       "\n",
       "        electricity         tools     hospitals         shops   aid_centers  \\\n",
       "count  26216.000000  26216.000000  26216.000000  26216.000000  26216.000000   \n",
       "mean       0.020293      0.006065      0.010795      0.004577      0.011787   \n",
       "std        0.141003      0.077643      0.103338      0.067502      0.107927   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       other_infrastructure  weather_related        floods         storm  \\\n",
       "count          26216.000000     26216.000000  26216.000000  26216.000000   \n",
       "mean               0.043904         0.278341      0.082202      0.093187   \n",
       "std                0.204887         0.448191      0.274677      0.290700   \n",
       "min                0.000000         0.000000      0.000000      0.000000   \n",
       "25%                0.000000         0.000000      0.000000      0.000000   \n",
       "50%                0.000000         0.000000      0.000000      0.000000   \n",
       "75%                0.000000         1.000000      0.000000      0.000000   \n",
       "max                1.000000         1.000000      1.000000      1.000000   \n",
       "\n",
       "               fire    earthquake          cold  other_weather  direct_report  \n",
       "count  26216.000000  26216.000000  26216.000000   26216.000000   26216.000000  \n",
       "mean       0.010757      0.093645      0.020217       0.052487       0.193584  \n",
       "std        0.103158      0.291340      0.140743       0.223011       0.395114  \n",
       "min        0.000000      0.000000      0.000000       0.000000       0.000000  \n",
       "25%        0.000000      0.000000      0.000000       0.000000       0.000000  \n",
       "50%        0.000000      0.000000      0.000000       0.000000       0.000000  \n",
       "75%        0.000000      0.000000      0.000000       0.000000       0.000000  \n",
       "max        1.000000      1.000000      1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove child alone field because it has all zeros only\n",
    "df = df.drop(['child_alone'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of 2's in the related field\n",
    "df['related'].eq(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 2 with 1 to consider it a valid response(binary).\n",
    "df['related']=df['related'].map(lambda x: 1 if x == 2 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract X and y variables from the data for the modelling\n",
    "X = df['message']\n",
    "#select from columns with categorical values 0 or 1\n",
    "y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text,url_place_holder_string=\"urlplaceholder\"):\n",
    "    \"\"\"\n",
    "    function to tokenize and normalize text data\n",
    "    \n",
    "    Arguments:\n",
    "        text -> messages to be tokenized and normalized\n",
    "    Output:\n",
    "        normalized -> List of tokens extracted and normalized from the messages\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace all urls with a urlplaceholder string\n",
    "    url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    \n",
    "    # Extract all the urls from the provided text \n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    \n",
    "    # Replace url with a url placeholder string\n",
    "    for detected_url in detected_urls:\n",
    "        text = text.replace(detected_url, url_place_holder_string)\n",
    "\n",
    "    # Extract the word tokens from the provided text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    #Lemmanitizer to remove inflectional and derivationally related forms of a word\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "    # List of clean tokens\n",
    "    normalized = [lemmatizer.lemmatize(w).lower().strip() for w in tokens]\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a custom transformer which will extract the starting verb of a sentence\n",
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    The class for implementing Verb Extractor\n",
    "    \n",
    "    This class extract the starting verb of a sentence,\n",
    "    creating a new feature for the ML classifier\n",
    "    \"\"\"\n",
    "\n",
    "    def starting_verb(self, text):\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        for sentence in sentence_list:\n",
    "            pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "            first_word, first_tag = pos_tags[0]\n",
    "            if first_tag in ['VB', 'VBP'] or first_word == 'RT':\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        return pd.DataFrame(X_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_one = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('count_vectorizer', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf_transformer', TfidfTransformer())\n",
    "            ]))\n",
    "            \n",
    "        ])),\n",
    "\n",
    "        ('classifier', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "    ])\n",
    "\n",
    "pipeline_two = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('count_vectorizer', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf_transformer', TfidfTransformer())\n",
    "            ])),\n",
    "\n",
    "            ('starting_verb_transformer', StartingVerbExtractor())\n",
    "        ])),\n",
    "\n",
    "        ('classifier', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "pipeline_fitted = pipeline_one.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.84      0.94      0.89      5058\n",
      "               request       0.80      0.54      0.64      1100\n",
      "                 offer       0.09      0.03      0.05        30\n",
      "           aid_related       0.77      0.59      0.67      2719\n",
      "          medical_help       0.63      0.31      0.42       504\n",
      "      medical_products       0.70      0.32      0.44       309\n",
      "     search_and_rescue       0.60      0.17      0.26       189\n",
      "              security       0.11      0.02      0.03       112\n",
      "              military       0.67      0.36      0.46       233\n",
      "                 water       0.73      0.64      0.69       399\n",
      "                  food       0.81      0.68      0.74       712\n",
      "               shelter       0.79      0.58      0.67       585\n",
      "              clothing       0.68      0.40      0.50       100\n",
      "                 money       0.58      0.32      0.41       153\n",
      "        missing_people       0.57      0.18      0.27        72\n",
      "              refugees       0.60      0.26      0.37       232\n",
      "                 death       0.79      0.50      0.61       316\n",
      "             other_aid       0.48      0.15      0.23       850\n",
      "infrastructure_related       0.38      0.09      0.15       435\n",
      "             transport       0.66      0.25      0.36       318\n",
      "             buildings       0.68      0.40      0.50       349\n",
      "           electricity       0.59      0.31      0.41       141\n",
      "                 tools       0.22      0.05      0.08        39\n",
      "             hospitals       0.32      0.13      0.18        63\n",
      "                 shops       0.00      0.00      0.00        33\n",
      "           aid_centers       0.42      0.11      0.17        74\n",
      "  other_infrastructure       0.18      0.05      0.07       299\n",
      "       weather_related       0.86      0.67      0.75      1876\n",
      "                floods       0.84      0.56      0.67       561\n",
      "                 storm       0.78      0.47      0.59       642\n",
      "                  fire       0.51      0.27      0.36        73\n",
      "            earthquake       0.86      0.80      0.83       618\n",
      "                  cold       0.70      0.29      0.41       156\n",
      "         other_weather       0.46      0.12      0.19       342\n",
      "         direct_report       0.72      0.46      0.56      1260\n",
      "\n",
      "             micro avg       0.78      0.59      0.67     20952\n",
      "             macro avg       0.58      0.34      0.42     20952\n",
      "          weighted avg       0.74      0.59      0.64     20952\n",
      "           samples avg       0.65      0.51      0.53     20952\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_prediction_train = pipeline_fitted.predict(X_train)\n",
    "y_prediction_test = pipeline_fitted.predict(X_test)\n",
    "\n",
    "# Print classification report on test data\n",
    "print(classification_report(y_test.values, y_prediction_test, target_names=y.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.95      0.88     15036\n",
      "               request       0.79      0.55      0.65      3374\n",
      "                 offer       0.42      0.09      0.15        88\n",
      "           aid_related       0.77      0.60      0.68      8141\n",
      "          medical_help       0.65      0.27      0.38      1580\n",
      "      medical_products       0.70      0.32      0.44      1004\n",
      "     search_and_rescue       0.67      0.23      0.34       535\n",
      "              security       0.42      0.08      0.13       359\n",
      "              military       0.68      0.35      0.46       627\n",
      "                 water       0.77      0.66      0.71      1273\n",
      "                  food       0.81      0.70      0.75      2211\n",
      "               shelter       0.78      0.54      0.64      1729\n",
      "              clothing       0.80      0.47      0.59       305\n",
      "                 money       0.59      0.31      0.40       451\n",
      "        missing_people       0.64      0.19      0.29       226\n",
      "              refugees       0.65      0.28      0.40       643\n",
      "                 death       0.77      0.50      0.60       878\n",
      "             other_aid       0.57      0.16      0.25      2596\n",
      "infrastructure_related       0.56      0.13      0.21      1270\n",
      "             transport       0.80      0.24      0.37       883\n",
      "             buildings       0.70      0.42      0.52       984\n",
      "           electricity       0.65      0.33      0.44       391\n",
      "                 tools       0.58      0.06      0.11       120\n",
      "             hospitals       0.43      0.14      0.21       220\n",
      "                 shops       0.62      0.09      0.16        87\n",
      "           aid_centers       0.43      0.10      0.16       235\n",
      "  other_infrastructure       0.50      0.11      0.18       852\n",
      "       weather_related       0.86      0.67      0.75      5421\n",
      "                floods       0.87      0.56      0.68      1594\n",
      "                 storm       0.79      0.53      0.63      1801\n",
      "                  fire       0.67      0.35      0.46       209\n",
      "            earthquake       0.89      0.79      0.83      1837\n",
      "                  cold       0.78      0.39      0.52       374\n",
      "         other_weather       0.56      0.17      0.26      1034\n",
      "         direct_report       0.74      0.49      0.59      3815\n",
      "\n",
      "             micro avg       0.79      0.60      0.68     62183\n",
      "             macro avg       0.68      0.37      0.45     62183\n",
      "          weighted avg       0.76      0.60      0.65     62183\n",
      "           samples avg       0.65      0.52      0.53     62183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report on training data\n",
    "print('\\n',classification_report(y_train.values, y_prediction_train, target_names=y.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('text_pipeline',\n",
       "                                                                        Pipeline(steps=[('count_vectorizer',\n",
       "                                                                                         CountVectorizer(tokenizer=<function tokenize at 0x13eb9e320>)),\n",
       "                                                                                        ('tfidf_transformer',\n",
       "                                                                                         TfidfTransformer())]))])),\n",
       "                                       ('classifier',\n",
       "                                        MultiOutputClassifier(estimator=AdaBoostClassifier()))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__estimator__learning_rate': [0.01, 0.02,\n",
       "                                                                  0.05],\n",
       "                         'classifier__estimator__n_estimators': [10, 20, 40]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline_one.get_params().keys()\n",
    "parameters_grid = {'classifier__estimator__learning_rate': [0.01, 0.02, 0.05],\n",
    "              'classifier__estimator__n_estimators': [10, 20, 40]}\n",
    "\n",
    "#parameters_grid = {'classifier__estimator__n_estimators': [10, 20, 40]}\n",
    "\n",
    "cv = GridSearchCV(pipeline_one, param_grid=parameters_grid, scoring='f1_micro', n_jobs=-1)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prediction values from the grid search cross validator\n",
    "y_prediction_test = cv.predict(X_test)\n",
    "y_prediction_train = cv.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.77      1.00      0.87      5058\n",
      "               request       0.61      0.39      0.47      1100\n",
      "                 offer       0.00      0.00      0.00        30\n",
      "           aid_related       0.81      0.18      0.30      2719\n",
      "          medical_help       0.68      0.13      0.21       504\n",
      "      medical_products       0.76      0.13      0.22       309\n",
      "     search_and_rescue       0.56      0.15      0.24       189\n",
      "              security       0.00      0.00      0.00       112\n",
      "              military       0.00      0.00      0.00       233\n",
      "                 water       0.57      0.85      0.68       399\n",
      "                  food       0.78      0.67      0.72       712\n",
      "               shelter       0.86      0.31      0.45       585\n",
      "              clothing       0.67      0.28      0.39       100\n",
      "                 money       0.00      0.00      0.00       153\n",
      "        missing_people       0.56      0.21      0.30        72\n",
      "              refugees       1.00      0.02      0.03       232\n",
      "                 death       0.67      0.01      0.01       316\n",
      "             other_aid       0.00      0.00      0.00       850\n",
      "infrastructure_related       0.00      0.00      0.00       435\n",
      "             transport       0.57      0.26      0.36       318\n",
      "             buildings       0.00      0.00      0.00       349\n",
      "           electricity       0.00      0.00      0.00       141\n",
      "                 tools       0.00      0.00      0.00        39\n",
      "             hospitals       0.00      0.00      0.00        63\n",
      "                 shops       0.00      0.00      0.00        33\n",
      "           aid_centers       0.00      0.00      0.00        74\n",
      "  other_infrastructure       0.00      0.00      0.00       299\n",
      "       weather_related       0.91      0.22      0.36      1876\n",
      "                floods       0.92      0.36      0.52       561\n",
      "                 storm       0.74      0.26      0.38       642\n",
      "                  fire       0.43      0.37      0.40        73\n",
      "            earthquake       0.88      0.66      0.76       618\n",
      "                  cold       0.76      0.24      0.36       156\n",
      "         other_weather       0.56      0.11      0.19       342\n",
      "         direct_report       0.63      0.37      0.47      1260\n",
      "\n",
      "             micro avg       0.75      0.43      0.55     20952\n",
      "             macro avg       0.45      0.21      0.25     20952\n",
      "          weighted avg       0.66      0.43      0.46     20952\n",
      "           samples avg       0.71      0.45      0.49     20952\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report on test data\n",
    "print(classification_report(y_test.values, y_prediction_test, target_names=y.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               related       0.76      1.00      0.87     15036\n",
      "               request       0.61      0.39      0.47      3374\n",
      "                 offer       1.00      0.02      0.04        88\n",
      "           aid_related       0.80      0.19      0.31      8141\n",
      "          medical_help       0.62      0.11      0.19      1580\n",
      "      medical_products       0.72      0.13      0.22      1004\n",
      "     search_and_rescue       0.67      0.19      0.30       535\n",
      "              security       0.00      0.00      0.00       359\n",
      "              military       0.00      0.00      0.00       627\n",
      "                 water       0.58      0.84      0.69      1273\n",
      "                  food       0.77      0.68      0.72      2211\n",
      "               shelter       0.84      0.29      0.43      1729\n",
      "              clothing       0.78      0.32      0.46       305\n",
      "                 money       1.00      0.01      0.02       451\n",
      "        missing_people       0.70      0.27      0.39       226\n",
      "              refugees       0.70      0.01      0.02       643\n",
      "                 death       0.78      0.01      0.02       878\n",
      "             other_aid       0.00      0.00      0.00      2596\n",
      "infrastructure_related       0.00      0.00      0.00      1270\n",
      "             transport       0.58      0.24      0.34       883\n",
      "             buildings       0.00      0.00      0.00       984\n",
      "           electricity       0.00      0.00      0.00       391\n",
      "                 tools       0.00      0.00      0.00       120\n",
      "             hospitals       0.00      0.00      0.00       220\n",
      "                 shops       0.00      0.00      0.00        87\n",
      "           aid_centers       0.00      0.00      0.00       235\n",
      "  other_infrastructure       0.00      0.00      0.00       852\n",
      "       weather_related       0.91      0.22      0.36      5421\n",
      "                floods       0.91      0.33      0.48      1594\n",
      "                 storm       0.74      0.26      0.38      1801\n",
      "                  fire       0.55      0.42      0.47       209\n",
      "            earthquake       0.90      0.65      0.75      1837\n",
      "                  cold       0.66      0.21      0.32       374\n",
      "         other_weather       0.58      0.13      0.21      1034\n",
      "         direct_report       0.63      0.39      0.48      3815\n",
      "\n",
      "             micro avg       0.75      0.43      0.55     62183\n",
      "             macro avg       0.51      0.21      0.26     62183\n",
      "          weighted avg       0.66      0.43      0.46     62183\n",
      "           samples avg       0.71      0.44      0.49     62183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report on training data\n",
    "print('\\n',classification_report(y_train.values, y_prediction_train, target_names=y.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.94      0.88      5031\n",
      "               request       0.75      0.54      0.63      1106\n",
      "                 offer       0.00      0.00      0.00        34\n",
      "           aid_related       0.77      0.60      0.67      2760\n",
      "          medical_help       0.58      0.27      0.37       500\n",
      "      medical_products       0.62      0.25      0.36       322\n",
      "     search_and_rescue       0.46      0.16      0.24       190\n",
      "              security       0.23      0.05      0.08       124\n",
      "              military       0.64      0.38      0.48       214\n",
      "                 water       0.72      0.65      0.69       401\n",
      "                  food       0.80      0.67      0.73       736\n",
      "               shelter       0.79      0.56      0.65       589\n",
      "              clothing       0.71      0.34      0.46       119\n",
      "                 money       0.62      0.35      0.45       165\n",
      "        missing_people       0.57      0.22      0.32        91\n",
      "              refugees       0.65      0.22      0.33       249\n",
      "                 death       0.76      0.45      0.57       309\n",
      "             other_aid       0.56      0.14      0.23       929\n",
      "infrastructure_related       0.47      0.11      0.18       406\n",
      "             transport       0.62      0.23      0.34       336\n",
      "             buildings       0.66      0.40      0.50       334\n",
      "           electricity       0.55      0.27      0.36       144\n",
      "                 tools       0.11      0.03      0.05        35\n",
      "             hospitals       0.31      0.12      0.18        64\n",
      "                 shops       0.00      0.00      0.00        26\n",
      "           aid_centers       0.26      0.08      0.13        72\n",
      "  other_infrastructure       0.38      0.11      0.17       281\n",
      "       weather_related       0.86      0.65      0.74      1859\n",
      "                floods       0.87      0.56      0.68       579\n",
      "                 storm       0.76      0.55      0.64       632\n",
      "                  fire       0.55      0.17      0.26        69\n",
      "            earthquake       0.87      0.74      0.80       609\n",
      "                  cold       0.66      0.33      0.44       122\n",
      "         other_weather       0.57      0.15      0.24       343\n",
      "         direct_report       0.73      0.49      0.59      1260\n",
      "\n",
      "             micro avg       0.78      0.58      0.67     21040\n",
      "             macro avg       0.58      0.34      0.41     21040\n",
      "          weighted avg       0.74      0.58      0.63     21040\n",
      "           samples avg       0.64      0.51      0.52     21040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use pipeline_two which includes StartingVerbEstimator\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "pipeline_fitted = pipeline_two.fit(X_train, y_train)\n",
    "\n",
    "y_prediction_train = pipeline_fitted.predict(X_train)\n",
    "y_prediction_test = pipeline_fitted.predict(X_test)\n",
    "\n",
    "# Print classification report on test data\n",
    "print(classification_report(y_test.values, y_prediction_test, target_names=y.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.94      0.88     15063\n",
      "               request       0.80      0.55      0.65      3368\n",
      "                 offer       0.18      0.05      0.08        84\n",
      "           aid_related       0.77      0.59      0.67      8100\n",
      "          medical_help       0.65      0.28      0.39      1584\n",
      "      medical_products       0.70      0.34      0.46       991\n",
      "     search_and_rescue       0.73      0.26      0.38       534\n",
      "              security       0.54      0.09      0.15       347\n",
      "              military       0.70      0.37      0.48       646\n",
      "                 water       0.78      0.68      0.73      1271\n",
      "                  food       0.81      0.69      0.75      2187\n",
      "               shelter       0.79      0.54      0.64      1725\n",
      "              clothing       0.78      0.43      0.55       286\n",
      "                 money       0.58      0.31      0.41       439\n",
      "        missing_people       0.71      0.19      0.30       207\n",
      "              refugees       0.63      0.25      0.36       626\n",
      "                 death       0.77      0.51      0.61       885\n",
      "             other_aid       0.57      0.15      0.24      2517\n",
      "infrastructure_related       0.54      0.11      0.18      1299\n",
      "             transport       0.72      0.31      0.43       865\n",
      "             buildings       0.72      0.42      0.53       999\n",
      "           electricity       0.67      0.31      0.42       388\n",
      "                 tools       0.41      0.06      0.10       124\n",
      "             hospitals       0.49      0.14      0.22       219\n",
      "                 shops       0.22      0.02      0.04        94\n",
      "           aid_centers       0.48      0.14      0.22       237\n",
      "  other_infrastructure       0.47      0.12      0.19       870\n",
      "       weather_related       0.87      0.66      0.75      5438\n",
      "                floods       0.87      0.57      0.69      1576\n",
      "                 storm       0.78      0.54      0.64      1811\n",
      "                  fire       0.68      0.23      0.35       213\n",
      "            earthquake       0.89      0.79      0.84      1846\n",
      "                  cold       0.73      0.34      0.46       408\n",
      "         other_weather       0.52      0.15      0.23      1033\n",
      "         direct_report       0.76      0.49      0.60      3815\n",
      "\n",
      "             micro avg       0.80      0.59      0.68     62095\n",
      "             macro avg       0.66      0.36      0.45     62095\n",
      "          weighted avg       0.77      0.59      0.65     62095\n",
      "           samples avg       0.65      0.52      0.53     62095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report on training data\n",
    "print('\\n',classification_report(y_train.values, y_prediction_train, target_names=y.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_file = pickle.dumps('classifier.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disasterresponse-env",
   "language": "python",
   "name": "disasterresponse-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
